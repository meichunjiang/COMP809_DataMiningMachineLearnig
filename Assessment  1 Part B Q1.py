'''
@ ORG:          Auckland University of Technology
@ Courses:      [COMP809]Data Mining and Machine Learning Sem 2, 2020
@ Assessment:   Assessment 1 Part B Q1
@ Author:       Chunjiang Mei
@ Student ID:   20100106
@ Time:         23/08/2020
'''

'''
In this question you will investigate two different methods of combining two different types of classifiers.
The dataset that you will be experimenting with is the Forest Type Mapping dataset which can be found from Blackboard
under the Assessments 1 folder.The dataset contains information on four different forest types
( 's' ('Sugi' forest), 'h' ('Hinoki' forest), 'd' ('Mixed deciduous' forest), 'o' ('Other' non-forest land)and the
objective is to detect (classify) which of the four types of forest that a particular data sample is extracted from.
Use 70% of the data for training and the rest for testing.

Use Python for the implementation.
'''
import pandas                   as pd
import numpy                    as np
import matplotlib.pyplot        as plt
#import tensorflow               as tf
from sklearn.model_selection    import train_test_split
from sklearn.neural_network     import MLPClassifier
from sklearn.tree               import DecisionTreeClassifier
from sklearn.metrics            import confusion_matrix
print('=============================== Assessment 1 Part B Q1 Start ===============================')
'''
1.The first step is to generate and validate models for each classifier type individually.
  Use the Decision Tree and the Multi-Layer Perceptron to build individual models.

  Display the confusion matrix for each classifier together with the overall classification accuracy generated
  on the testing segment. Submit the Python code for this task.[3 marks]
'''
print('+++++++++++++++ Question 1-(1) [3 marks]+++++++++++++++')
# [Step 1] Loading DataSetse
rawdata = pd.read_excel('/Users/chunjiangmei/Documents/Forest.xlsx')
X,Y = rawdata.iloc[:, [1,-1]].values, rawdata.iloc[:, 0].values
X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.3)
# Data Reshape?
#print("[ Data summary is as follow : ]\n",rawdata.describe(),"[ Data Columns is as follow : ]\n",rawdata.columns)
#print('X_train len is',len(X_train),'\nX_test  len is',len(X_test),'\nY_train len is',len(Y_train),'\nY_test  len is',len(Y_test))

# Build Decision Tree Model
clf_dTree = DecisionTreeClassifier()                                            # Building
clf_dTree = clf_dTree.fit(X_train,Y_train)                                      # Training
Y_pred = clf_dTree.predict(X_test)                                              # Predicting
print('The accuracy of Decision Tree Model is ',clf_dTree.score(X_test,Y_test)) # Accuracy
print ('The confusion matrix of DecisionTreeClassifier is as follow:\n',
       confusion_matrix(Y_test,Y_pred) )                                        # The confusion matrix of testing segment

# Build MLP Model
clf_MLP = MLPClassifier( solver ='adam',activation='relu'
                        ,alpha=1e-4,hidden_layer_sizes=(10,10)
                        ,random_state=1,learning_rate_init=.1)      # Building
clf_MLP = clf_MLP.fit(X_train,Y_train)                                          # Training
Y_pred  = clf_MLP.predict(X_test)                                               # Predicting
print('The accuracy of MLP Model is ',clf_MLP.score(X_test,Y_test))             # Accuracy
print ('The confusion matrix of Multi-Layer Perceptron is as follow:\n',
       confusion_matrix(Y_test,Y_pred) )                                        # The confusion matrix of testing segment
'''
2.Using the models generated in part 1 of this question, generate the probability for each class and for each
  classifier and for each sample in the testing segment. This should result in 8 probability values for each sample.

  a)Submit the Python code for computing the above probabilities. If continuing with the same codebase from part 1 of 
    this question, then highlight the additional code you used.[5 marks]
  b)Display the probabilities for the first sample of the test segment of the dataset in a 4 by 2 table where the rows 
    denote class values and the columns denote the type of classifier.[2 marks]
'''
print('\n+++++++++++++++ Question 1-(2) [7 marks]+++++++++++++++')
proba = pd.DataFrame([[-1,-1],[-1,-1],[-1,-1],[-1,-1]],index=[ 'd','h', 'o','s'],columns=['MLP','DecisionTree'])
proba.iloc[:,1] = clf_dTree.predict_proba(X_test)[0]#返回的是类别对应的概率，其他回答结合代码举例很详细了，我主要讲一下顺序问题。概率对应的是类别按字母排序，可以通过模型.classes_ 查看类别
proba.iloc[:,0] = clf_MLP.predict_proba(X_test)[0]
print('The probabilities for the first sample of the test segment of the dataset:\n',proba)

'''
3.Using the probabilities generated by the two classifiers for each sample, formulate a method of assigning a class for 
  a given sample in the test segment. Your method must be based on the Average Aggregate function.
  Your method must be given in pseudo code form
  (Please ensure that you use high level English statements and not Python-like statements). [6 marks]
'''
print('\n+++++++++++++++ Question 1-(3) [6 marks]+++++++++++++++')
'''
4.Implement the method that you used in part 3 of this question in Python code. Submit the Python code that you developed.
  Run the method and produce the classification accuracy on the test segment.[6 marks]
'''
print('\n+++++++++++++++ Question 1-(4) [6 marks]+++++++++++++++')
'''
    5.In this part we will explore a different approach to combining the two classifiers.
      Instead of performing an aggregation that is based on the Average operator we will use conditional probabilities.
      With this method we will multiply the maximum probability returned by a classifier by its conditional probability.

      Thus for example if the maximum probability across the four different classes returned by the Decision Tree
      classifier for a given sample was 0.6. Suppose that it was returned for class ‘s’. We then compute P1=0.6*Pr(class=’s’|DT=’s’).

      At the same time if  the maximum probability (across the classes) returned by the MLP classifier for that same
      sample was 0.7 and it was for class ‘h’, then we compute P2=0.7*Pr(class=’h’|MLP=’h’).

      The final class returned by the combined classifier for the sample would be ‘s’ if P1>P2 else it would be ‘h’.

       a)Describe an efficient method for evaluating the conditional probabilities required for P1 and P2 above.[3 marks]
       b)Give one advantage of this method over the method that you proposed in part 3 of this question. [3 marks]
'''
print('+++++++++++++++ Question 1-(5) [6 marks]+++++++++++++++')
'''
    6.Implement the method that you used in part 5 of this question in Python code.
      Submit the Python code that you used.[7 marks]
'''
print('+++++++++++++++ Question 1-(6) [7 marks]+++++++++++++++')
print('=============================== Assessment 1 Part B Q1 End ===============================')